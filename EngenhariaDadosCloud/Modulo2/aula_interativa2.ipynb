{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "JcebP664JNoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22a36f9a-08de-4d40-a343-76e5a1e83bac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=be4cc0eb4cb22a87744b5d1bc93fcf6b3e3f5d30e592bca547df1d63ac3394e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hNpKkP72y-Sf",
        "outputId": "79e96c28-9de8-4848-e224-08e2a9a8a3aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.3.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Spark entry point\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Aula Interativa 2 - Apache Spark\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.version\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi_cE3c1JwTC",
        "outputId": "42237236-7af6-4253-a19a-eb65c928d909"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zt3StHkjy-Sp",
        "outputId": "63579c8f-94d6-4d79-f08b-09140e57c61e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- PassengerId: integer (nullable = true)\n",
            " |-- Survived: integer (nullable = true)\n",
            " |-- Pclass: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- SibSp: integer (nullable = true)\n",
            " |-- Parch: integer (nullable = true)\n",
            " |-- Ticket: string (nullable = true)\n",
            " |-- Fare: double (nullable = true)\n",
            " |-- Cabin: string (nullable = true)\n",
            " |-- Embarked: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "titanic_df = spark.read.csv('/content/drive/MyDrive/MBA/titanic-3.csv',header='True',inferSchema='True')\n",
        "\n",
        "titanic_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MX-aznARy-Sr",
        "outputId": "046e28f0-001f-4f36-d352-e81ae176c0d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "891"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "titanic_df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDBO6UCJy-Ss",
        "outputId": "30bcb945-f25a-4431-d01d-add96e4e3d91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|survived|count|\n",
            "+--------+-----+\n",
            "|       1|  342|\n",
            "|       0|  549|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "titanic_df.groupBy('survived').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ujGqcGloy-St",
        "outputId": "6a680673-541b-4e11-c814-11cf731ccab6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+\n",
            "|survived|count(1)|\n",
            "+--------+--------+\n",
            "|       1|     342|\n",
            "|       0|     549|\n",
            "+--------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "titanic_df.createOrReplaceTempView('table')\n",
        "\n",
        "spark.sql(\"SELECT survived, count(*) FROM table GROUP BY survived\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00ahemyDy-Su",
        "outputId": "64ca0d40-13d1-4a13-8922-ad99536908f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------------+\n",
            "|survived|         avg(Fare)|\n",
            "+--------+------------------+\n",
            "|       1| 48.39540760233917|\n",
            "|       0|22.117886885245877|\n",
            "+--------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "titanic_df.groupBy('survived').agg({\"Fare\": \"avg\"}).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rknf4y6Zy-Sv",
        "outputId": "18ca5ed9-42ce-4440-b6e8-3a5712c8bdca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------------+\n",
            "|survived|         avg(fare)|\n",
            "+--------+------------------+\n",
            "|       1| 48.39540760233917|\n",
            "|       0|22.117886885245877|\n",
            "+--------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"SELECT survived, avg(fare) FROM table GROUP BY survived\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJ93m3qBy-Sw",
        "outputId": "a26cf525-ea5d-4778-d6d0-c9a8894c6b0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+\n",
            "| age|age_count|\n",
            "+----+---------+\n",
            "|null|       52|\n",
            "|24.0|       15|\n",
            "|35.0|       11|\n",
            "|27.0|       11|\n",
            "|36.0|       11|\n",
            "|22.0|       11|\n",
            "|30.0|       10|\n",
            "|18.0|        9|\n",
            "|32.0|        9|\n",
            "|19.0|        9|\n",
            "|31.0|        8|\n",
            "|29.0|        8|\n",
            "| 4.0|        7|\n",
            "|28.0|        7|\n",
            "|34.0|        6|\n",
            "|25.0|        6|\n",
            "|42.0|        6|\n",
            "|40.0|        6|\n",
            "|48.0|        6|\n",
            "|33.0|        6|\n",
            "+----+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"SELECT age, count(*) as age_count FROM table WHERE survived == 1 GROUP BY age ORDER BY age_count DESC\").show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "N9SwagvOy-Sw",
        "outputId": "7df37a9e-e3e9-470a-9b94-9f3bdb1cc88d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|     uppercase(Name)|                Name|\n",
            "+--------------------+--------------------+\n",
            "|BRAUND, MR. OWEN ...|Braund, Mr. Owen ...|\n",
            "|CUMINGS, MRS. JOH...|Cumings, Mrs. Joh...|\n",
            "|HEIKKINEN, MISS. ...|Heikkinen, Miss. ...|\n",
            "|FUTRELLE, MRS. JA...|Futrelle, Mrs. Ja...|\n",
            "|ALLEN, MR. WILLIA...|Allen, Mr. Willia...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# UDFs ajudam plugar funções complexas no SQL.\n",
        "from pyspark.sql.functions import udf\n",
        "\n",
        "def uppercase(str):\n",
        "    return str.upper()\n",
        "\n",
        "def ml_model(data):\n",
        "    return model(data)\n",
        "\n",
        "def maior_idade(age):\n",
        "  return age is None or age > 18\n",
        "\n",
        "spark.udf.register(\"uppercase\", uppercase)\n",
        "spark.udf.register(\"maior_idade\", maior_idade)\n",
        "\n",
        "spark.sql(\"SELECT uppercase(Name), Name from table WHERE maior_idade(Age) == TRUE\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kifXsRvvy-Sx"
      },
      "outputs": [],
      "source": [
        "# https://sparkbyexamples.com/spark/spark-write-dataframe-to-csv-file/\n",
        "\n",
        "spark.sql(\"SELECT uppercase(Name), Age from table\").write.option(\"header\", True).format(\"csv\").save(\"/content/drive/MyDrive/MBA/names\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "a8cl4jyay-Sy"
      },
      "outputs": [],
      "source": [
        "# https://sparkbyexamples.com/spark/spark-read-and-write-json-file/\n",
        "\n",
        "\n",
        "spark.sql(\"SELECT age, count(*) as age_count FROM table WHERE survived == 1 GROUP BY age ORDER BY age_count DESC\").write.format(\"json\").save(\"/content/drive/MyDrive/MBA/ages\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g--gk15Oy-Sy"
      },
      "outputs": [],
      "source": [
        "# https://spark.apache.org/docs/latest/sql-data-sources-jdbc.html\n",
        "    \n",
        "\n",
        "# Saving data to a JDBC source\n",
        "#jdbcDF.write \\\n",
        "#    .format(\"jdbc\") \\\n",
        "#    .option(\"url\", \"jdbc:postgresql:dbserver\") \\\n",
        "#    .option(\"dbtable\", \"schema.tablename\") \\\n",
        "#    .option(\"user\", \"username\") \\\n",
        "#    .option(\"password\", \"password\") \\\n",
        "#    .save()\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}